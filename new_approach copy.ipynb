{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric.transforms as ttr\n",
    "from astropy import table as astropy_table\n",
    "\n",
    "from mptd.reader import get_raw_data\n",
    "from mptd.simple_message import SimpleMessage\n",
    "from mptd.plotter import plot_data, plot_clusters, plot_fits_data\n",
    "from mptd.smallest_enclosing_circle import welzl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPTDData(Data):\n",
    "    def __init__(self, x = None, edge_index = None, edge_attr = None, y = None, pos = None, **kwargs):\n",
    "        if x is None:\n",
    "            x = torch.ones((1,pos.shape[0]), device=pos.device)\n",
    "        super().__init__(x, edge_index, edge_attr, y, pos, **kwargs)\n",
    "    \n",
    "    def append(self, other):\n",
    "        new_edge_index = torch.hstack([self.edge_index, other.edge_index]) \\\n",
    "                         if other.edge_index is not None and self.edge_index is not None else None\n",
    "        new_edge_attr = torch.hstack([self.edge_attr, other.edge_attr]) \\\n",
    "                        if other.edge_attr is not None and self.edge_attr is not None else None\n",
    "        \n",
    "        return MPTDData(x=torch.vstack([self.x, other.x]), \n",
    "                        y=torch.hstack([self.y, other.y]), \n",
    "                        pos=torch.vstack([self.y, other.y]), \n",
    "                        edge_index=new_edge_index,\n",
    "                        edge_attr=new_edge_attr\n",
    "                        )    \n",
    "    \n",
    "class MPTDDataset:\n",
    "    def __init__(self, filename, keys, filters:dict, withsim=True) -> None:\n",
    "        ismos = filename.endswith(\"MIEVLF0000.FTZ\") or filename.endswith(\"MIEVLI0000.FTZ\")\n",
    "        lastcolname = \"PHA\" if ismos else \"TIME_RAW\"\n",
    "        keys_plus = keys + [lastcolname]\n",
    "        raw_data = get_raw_data(filename, keys_plus, filters)\n",
    "\n",
    "        issimulated = torch.from_numpy(np.array(raw_data[\"ISSIMULATED\"])).bool()\n",
    "        self.groups = torch.from_numpy(np.array(raw_data[lastcolname]))\n",
    "        self.groups[~issimulated] = -1\n",
    "\n",
    "        if withsim:\n",
    "            self.data = MPTDData(pos = torch.from_numpy(np.array([raw_data[key] for key in keys]).T).float(),\n",
    "                                 y = issimulated.long()).cuda()\n",
    "        else:\n",
    "            self.data = MPTDData(pos = torch.from_numpy(np.array([raw_data[key] for key in keys]).T[~issimulated]).float(),\n",
    "                                 y = issimulated[~issimulated].long()).cuda()\n",
    "            \n",
    "        self.keys = keys\n",
    "\n",
    "    def get_group(self, group):\n",
    "        indices = self.groups == group\n",
    "        return self.data.pos[indices]\n",
    "    \n",
    "    def list_groups(self):\n",
    "        return torch.unique(self.groups)\n",
    "\n",
    "class MPTDElaborator:\n",
    "    def __init__(self, dataset:MPTDDataset, transformer, keys, model) -> None:\n",
    "        self.dataset = dataset\n",
    "        self.net_data = transformer(dataset.data)\n",
    "        self.keys = keys\n",
    "        self.model = model\n",
    "        self.iterations = 0\n",
    "        self.elaborated_data = self.net_data.x\n",
    "\n",
    "    def sizes(self):\n",
    "        return self.elaborated_data[:, 0]\n",
    "    \n",
    "    def distances(self):\n",
    "        return torch.norm(self.net_data.pos[self.net_data.edge_index[0]] - self.net_data.pos[self.net_data.edge_index[1]], dim=1)\n",
    "    \n",
    "    def forward(self, iterations=1):\n",
    "        for _ in range(iterations):\n",
    "            self.elaborated_data += self.model.forward(self.elaborated_data, self.net_data.edge_index)\n",
    "            self.iterations += 1\n",
    "            self.elaborated_data /= self.elaborated_data.max()\n",
    "        return self.sizes()\n",
    "    \n",
    "    def forward_plot(self, iterations, plot_every=1, plot_after = 0, max_threshold=0.5):\n",
    "        self.forward(iterations=plot_after)\n",
    "        while self.iterations < iterations:\n",
    "            sizes = self.sizes()\n",
    "            # threshold = torch.quantile(sizes, quantile).item()\n",
    "            threshold = min(sizes.mean().item(), max_threshold)\n",
    "            mask = sizes >= threshold\n",
    "            plot_data(self.net_data.pos[mask].cpu(), sizes[mask].cpu(), issimulated=self.net_data.y[mask].cpu().bool(), keys=self.keys, title=f\"iteration {self.iterations+1}\", outfile=osp.join(\"video_frames\", f\"frame_{i:02}.png\"))\n",
    "            self.forward(iterations=min(iterations - self.iterations, plot_every))\n",
    "\n",
    "        return self.sizes()\n",
    "\n",
    "class MPTDClusterer:\n",
    "    def __init__(self, algorithm, max_threshold):\n",
    "        self.max_threshold = max_threshold\n",
    "        self.algorithm = algorithm\n",
    "\n",
    "    def mask(self, elaborator:MPTDElaborator):\n",
    "        sizes = elaborator.sizes()\n",
    "        threshold = min(sizes.mean().item(), self.max_threshold)\n",
    "        mask = sizes >= threshold\n",
    "        return mask\n",
    "\n",
    "    def mask_data(self, elaborator:MPTDElaborator):\n",
    "        mask = self.mask(elaborator)\n",
    "        masked_data = MPTDData(x=elaborator.net_data.x[mask], y= elaborator.net_data.y[mask]).cpu()\n",
    "        return masked_data\n",
    "    \n",
    "    def cluster(self, elaborator:MPTDElaborator):\n",
    "        masked_data, mask = self.mask_data(elaborator)\n",
    "        labels = self.algorithm.fit_predict(masked_data.pos)\n",
    "        labels_full = np.full((elaborator.net_data.pos.shape[0],), -1)\n",
    "        labels_full[mask.cpu()] = labels\n",
    "\n",
    "        return labels_full\n",
    "    \n",
    "class MPTDScorer:\n",
    "    def __init__(self, elaborator:MPTDElaborator):\n",
    "        self.dataset    = elaborator.dataset\n",
    "        self.elaborator = elaborator\n",
    "        self.labels = None\n",
    "\n",
    "    def predict_labels(self, clusterer:MPTDClusterer):\n",
    "        self.labels = clusterer.cluster(self.elaborator)\n",
    "        return self.labels\n",
    "    \n",
    "    def fluence_vs_success(self):\n",
    "        assert self.labels is not None\n",
    "        return count_and_check_coordinates_grouped(self.dataset.data.pos[self.dataset.data.y.bool()], self.dataset.groups[self.dataset.data.y.bool()], self.dataset.data.pos[self.labels >= 0])\n",
    "    \n",
    "    def cluster_accuracy(self):\n",
    "        assert self.labels is not None\n",
    "        return count_and_check_coordinates_grouped(self.dataset.data.pos[self.labels >= 0], self.labels[self.labels >= 0], self.dataset.data.pos[self.dataset.data.y.bool()]).T[1].mean()\n",
    "\n",
    "def count_and_check_coordinates(tensors_A, tensor_B):\n",
    "    # Initialize lists to store the number of points and presence information for each tensor A\n",
    "    num_points_list = []\n",
    "    contains_matching_coordinates_list = []\n",
    "\n",
    "    # Perform element-wise comparison for each tensor in tensors_A\n",
    "    for tensor_A in tensors_A:\n",
    "        # Broadcast tensor_B to have the same shape as tensor_A\n",
    "        expanded_B = tensor_B.unsqueeze(0)  # Shape: (1, B_points, 3)\n",
    "        expanded_B = expanded_B.expand(tensor_A.shape[0], -1, -1)  # Shape: (A_points, B_points, 3)\n",
    "\n",
    "        # Perform element-wise comparison to check for matching coordinates\n",
    "        matched_coordinates = torch.all(tensor_A.unsqueeze(1) == expanded_B, dim=-1)\n",
    "\n",
    "        # Use torch.any() to check if any coordinate in A matches any coordinate in B for this tensor A\n",
    "        contains_matching_coordinates = torch.any(matched_coordinates, dim=1)\n",
    "\n",
    "        # Append the number of points and presence information to their respective lists\n",
    "        num_points_list.append(tensor_A.shape[0])\n",
    "        contains_matching_coordinates_list.append(contains_matching_coordinates)\n",
    "\n",
    "    # Concatenate the lists to create tensors\n",
    "    num_points_in_A = torch.tensor(num_points_list, dtype=torch.int32).unsqueeze(-1)\n",
    "\n",
    "    contains_matching_coordinates_tensor = torch.tensor([elems.any(dim=-1) for elems in contains_matching_coordinates_list], dtype=bool).unsqueeze(1)\n",
    "\n",
    "    # Combine the information about the number of points and matching coordinates into a single tensor\n",
    "    result_tensor = torch.cat((num_points_in_A, contains_matching_coordinates_tensor.int()), dim=1)\n",
    "\n",
    "    return result_tensor\n",
    "\n",
    "def count_and_check_coordinates_grouped(tensor_coordinates, labels, tensor_B):\n",
    "    unique_labels = np.unique(labels)\n",
    "    tensors_A = []\n",
    "\n",
    "    for label in unique_labels:\n",
    "        # Get the coordinates for the current label\n",
    "        mask = labels == label\n",
    "        coordinates_for_label = tensor_coordinates[mask]\n",
    "\n",
    "        # Append the tensor with coordinates for this label to the list of tensors A\n",
    "        tensors_A.append(coordinates_for_label)\n",
    "\n",
    "    # Apply the function for each tensor in tensors_A and store the results in a list\n",
    "    results = count_and_check_coordinates(tensors_A, tensor_B)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Encountered an index error. Please ensure that all indices in 'edge_index' point to valid indices in the interval [0, 0] (got interval [1, 64515])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\transient_detection\\Lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:272\u001b[0m, in \u001b[0;36mMessagePassing._lift\u001b[1;34m(self, src, edge_index, dim)\u001b[0m\n\u001b[0;32m    271\u001b[0m     index \u001b[39m=\u001b[39m edge_index[dim]\n\u001b[1;32m--> 272\u001b[0m     \u001b[39mreturn\u001b[39;00m src\u001b[39m.\u001b[39;49mindex_select(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnode_dim, index)\n\u001b[0;32m    273\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mIndexError\u001b[39;00m, \u001b[39mRuntimeError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 28.03 GiB (GPU 0; 24.00 GiB total capacity; 46.74 MiB already allocated; 22.20 GiB free; 106.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m clusterer \u001b[39m=\u001b[39m MPTDClusterer(algorithm\u001b[39m=\u001b[39mdbscan, max_threshold\u001b[39m=\u001b[39mmax_threshold)\n\u001b[0;32m     18\u001b[0m scorer \u001b[39m=\u001b[39m MPTDScorer(elaborator)\n\u001b[1;32m---> 19\u001b[0m scorer\u001b[39m.\u001b[39;49melaborator\u001b[39m.\u001b[39;49mforward(iterations\u001b[39m=\u001b[39;49mlayers)\n\u001b[0;32m     20\u001b[0m scorer\u001b[39m.\u001b[39mpredict_labels(clusterer)\n",
      "Cell \u001b[1;32mIn[11], line 64\u001b[0m, in \u001b[0;36mMPTDElaborator.forward\u001b[1;34m(self, iterations)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, iterations\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(iterations):\n\u001b[1;32m---> 64\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39melaborated_data \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mforward(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49melaborated_data, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnet_data\u001b[39m.\u001b[39;49medge_index)\n\u001b[0;32m     65\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterations \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     66\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39melaborated_data \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39melaborated_data\u001b[39m.\u001b[39mmax()\n",
      "File \u001b[1;32mc:\\Users\\samuc\\Work\\MPTD\\mptd\\simple_message.py:48\u001b[0m, in \u001b[0;36mSimpleMessage.forward\u001b[1;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m received a tuple \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     42\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mof node features as input while this layer \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     43\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdoes not support bipartite message passing. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     44\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPlease try other layers such as \u001b[39m\u001b[39m'\u001b[39m\u001b[39mSAGEConv\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     45\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mGraphConv\u001b[39m\u001b[39m'\u001b[39m\u001b[39m instead\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     47\u001b[0m \u001b[39m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpropagate(edge_index, x\u001b[39m=\u001b[39;49mx, edge_weight\u001b[39m=\u001b[39;49medge_weight,\n\u001b[0;32m     49\u001b[0m                      size\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m     51\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\transient_detection\\Lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:459\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[1;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m decomp_args:\n\u001b[0;32m    457\u001b[0m         kwargs[arg] \u001b[39m=\u001b[39m decomp_kwargs[arg][i]\n\u001b[1;32m--> 459\u001b[0m coll_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_collect(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_user_args, edge_index, size,\n\u001b[0;32m    460\u001b[0m                           kwargs)\n\u001b[0;32m    462\u001b[0m msg_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minspector\u001b[39m.\u001b[39mdistribute(\u001b[39m'\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m'\u001b[39m, coll_dict)\n\u001b[0;32m    463\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_message_forward_pre_hooks\u001b[39m.\u001b[39mvalues():\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\transient_detection\\Lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:336\u001b[0m, in \u001b[0;36mMessagePassing._collect\u001b[1;34m(self, args, edge_index, size, kwargs)\u001b[0m\n\u001b[0;32m    334\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, Tensor):\n\u001b[0;32m    335\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_size(size, dim, data)\n\u001b[1;32m--> 336\u001b[0m             data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_lift(data, edge_index, dim)\n\u001b[0;32m    338\u001b[0m         out[arg] \u001b[39m=\u001b[39m data\n\u001b[0;32m    340\u001b[0m \u001b[39mif\u001b[39;00m is_torch_sparse_tensor(edge_index):\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\transient_detection\\Lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:275\u001b[0m, in \u001b[0;36mMessagePassing._lift\u001b[1;34m(self, src, edge_index, dim)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mIndexError\u001b[39;00m, \u001b[39mRuntimeError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    274\u001b[0m     \u001b[39mif\u001b[39;00m index\u001b[39m.\u001b[39mmin() \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m index\u001b[39m.\u001b[39mmax() \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m src\u001b[39m.\u001b[39msize(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnode_dim):\n\u001b[1;32m--> 275\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\n\u001b[0;32m    276\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEncountered an index error. Please ensure that all \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    277\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mindices in \u001b[39m\u001b[39m'\u001b[39m\u001b[39medge_index\u001b[39m\u001b[39m'\u001b[39m\u001b[39m point to valid indices in \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mthe interval [0, \u001b[39m\u001b[39m{\u001b[39;00msrc\u001b[39m.\u001b[39msize(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnode_dim)\u001b[39m \u001b[39m\u001b[39m-\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m] \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(got interval \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mint\u001b[39m(index\u001b[39m.\u001b[39mmin())\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mint\u001b[39m(index\u001b[39m.\u001b[39mmax())\u001b[39m}\u001b[39;00m\u001b[39m])\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    281\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    282\u001b[0m         \u001b[39mraise\u001b[39;00m e\n",
      "\u001b[1;31mIndexError\u001b[0m: Encountered an index error. Please ensure that all indices in 'edge_index' point to valid indices in the interval [0, 0] (got interval [1, 64515])"
     ]
    }
   ],
   "source": [
    "filename = osp.join(\"test.onD\", \"Icaro\", \"raw\", \"0690751601\", \"pps\", \"P0690751601M2S002MIEVLF0000.FTZ\") # easy example\n",
    "keys = [\"X\", \"TIME\", \"Y\"]\n",
    "k = 8\n",
    "layers = 50\n",
    "quantile = 0.999\n",
    "max_threshold = 0.90\n",
    "filters = {\"FLAG\": (0,4)}\n",
    "withsim = True\n",
    "min_samples = 5\n",
    "\n",
    "dataset = MPTDDataset(filename, keys, filters, withsim=withsim)\n",
    "transformer = ttr.KNNGraph(k=k, force_undirected=True)\n",
    "model = SimpleMessage()\n",
    "elaborator = MPTDElaborator(dataset,transformer,keys,model)\n",
    "eps = elaborator.distances().median().item()/2\n",
    "dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "clusterer = MPTDClusterer(algorithm=dbscan, max_threshold=max_threshold)\n",
    "scorer = MPTDScorer(elaborator)\n",
    "scorer.elaborator.forward(iterations=layers)\n",
    "scorer.predict_labels(clusterer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_elaboration(elaborator, layers, plot_every=1, plot_after = 0, max_threshold=0.5):\n",
    "    for i in range(layers):\n",
    "        elaborator.forward() \n",
    "        if (i+1)%plot_every == 0 and i >= plot_after:\n",
    "            sizes = elaborator.elaborated_data[:,0]\n",
    "            # threshold = torch.quantile(sizes, quantile).item()\n",
    "            threshold = min(sizes.mean().item(), max_threshold)\n",
    "            mask = sizes >= threshold\n",
    "            plot_data(elaborator.net_data.x[mask].cpu(), sizes[mask].cpu(), issimulated=elaborator.net_data.y[mask].cpu().bool(), keys=elaborator.keys, title=f\"iteration {i+1}\", outfile=osp.join(\"video_frames\", f\"frame_{i:02}.png\"))\n",
    "\n",
    "    return elaborator.elaborated_data[:, 0]\n",
    "\n",
    "def get_clusters(net_data, sizes, max_threshold, clusterer):\n",
    "    # threshold = torch.quantile(sizes, quantile).item()\n",
    "    threshold = min(sizes.mean().item(), max_threshold)\n",
    "    mask = sizes >= threshold\n",
    "    masked_data = SimTransientData(x=net_data.x[mask], y= net_data.y[mask]).cpu()\n",
    "\n",
    "    labels = clusterer.fit_predict(masked_data.x[:, 1:])\n",
    "    labels_full = np.full((net_data.x.shape[0],), -1)\n",
    "    labels_full[mask.cpu()] = labels\n",
    "\n",
    "    return labels_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = osp.join(\"test.onD\", \"Icaro\", \"raw\", \"0694730101\", \"pps\", \"P0694730101PNS003PIEVLF0000.FTZ\") # hard example\n",
    "filenames = []\n",
    "filenames.append(osp.join(\"test.onD\", \"Icaro\", \"raw\", \"0690751601\", \"pps\", \"P0690751601M1S001MIEVLF0000.FTZ\")) # easy example\n",
    "filenames.append(osp.join(\"test.onD\", \"Icaro\", \"raw\", \"0690751601\", \"pps\", \"P0690751601M2S002MIEVLF0000.FTZ\")) # easy example\n",
    "filenames.append(osp.join(\"test.onD\", \"Icaro\", \"raw\", \"0690751601\", \"pps\", \"P0690751601PNS003PIEVLF0000.FTZ\")) # easy example\n",
    "# filename = osp.join(\"test.onD\", \"Icaro\", \"raw\", \"0744440301\", \"pps\", \"P0744440301M1S001MIEVLF0000.FTZ\") # medium example\n",
    "keys = [\"PI\", \"X\", \"TIME\", \"Y\"]\n",
    "k = 8\n",
    "layers = 50\n",
    "quantile = 0.999\n",
    "max_threshold = 0.90\n",
    "withsim = True\n",
    "min_samples = 5\n",
    "\n",
    "raw_data = get_raw_data(filename=filenames[0], keys=keys, filters={\"FLAG\": (0,4)})\n",
    "for filename in filenames[1:]:\n",
    "    print(filename, len(raw_data))\n",
    "    raw_data = astropy_table.vstack([raw_data, get_raw_data(filename=filename, keys=keys, filters={\"FLAG\": (0,4)})])\n",
    "\n",
    "issimulated = torch.from_numpy(np.array(raw_data[\"ISSIMULATED\"])).bool()\n",
    "\n",
    "if withsim:\n",
    "    data = SimTransientData(x = torch.from_numpy(np.array([raw_data[key] for key in keys]).T).float(),\n",
    "                            y = issimulated.long()).cuda()\n",
    "else:\n",
    "    data = SimTransientData(x = torch.from_numpy(np.array([raw_data[key] for key in keys]).T[~issimulated]).float(),\n",
    "                            y = issimulated[~issimulated].long()).cuda()\n",
    "\n",
    "transform = ttr.KNNGraph(k=k, force_undirected=True)\n",
    "\n",
    "net_data =transform(data)\n",
    "\n",
    "distances = torch.norm(net_data.x[net_data.edge_index[0]] - net_data.x[net_data.edge_index[1]], dim=1)\n",
    "eps = distances.median().item()/2\n",
    "\n",
    "model = SimpleMessage()\n",
    "elaborator = MPTDElaborator(net_data, keys, model)\n",
    "sizes = get_elaborated(net_data, keys, model, layers, plot_every=1, plot_after = layers-1, max_threshold=max_threshold)\n",
    "\n",
    "dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "\n",
    "labels = get_clusters(net_data, distances, sizes, clusterer=dbscan, max_threshold=max_threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "def plot_mean_with_errorbars(tensor, labels, time_threshold=np.inf):\n",
    "    unique_labels = np.unique(labels)\n",
    "    fig, ax = plt.subplots()\n",
    "    colsm = plt.cm.ScalarMappable(norm=None, cmap=plt.cm.RdYlBu)\n",
    "    colsm\n",
    "\n",
    "    cbar_data = []  # Collect colorbar data\n",
    "    xs = []\n",
    "    xerrs = []\n",
    "    ys = []\n",
    "    yerrs = []\n",
    "    sizes = []\n",
    "    colors = []\n",
    "\n",
    "    for label in unique_labels:\n",
    "        if label == -1: continue\n",
    "        indices = np.where(labels == label)[0]\n",
    "        group_coords = tensor[indices]\n",
    "\n",
    "        mean_coords = torch.mean(group_coords, dim=0)\n",
    "        std_coords = torch.std(group_coords, dim=0)\n",
    "\n",
    "        size = np.log10(len(indices))*5\n",
    "        color = torch.std(group_coords[:, 1], dim=0)  # Standard deviation along the second dimension\n",
    "\n",
    "        if color > time_threshold: continue\n",
    "\n",
    "        cbar_data.append(color)  # Collect colorbar data\n",
    "        \n",
    "        # ax.errorbar(mean_coords[0], mean_coords[-1], xerr=std_coords[0], yerr=std_coords[-1],\n",
    "        #             fmt='o', markersize=size, color=plt.cm.RdYlBu(color.item()), alpha=0.7)\n",
    "        # print(plt.cm.RdYlBu(color.item()))\n",
    "\n",
    "        xs.append(mean_coords[0].item())\n",
    "        xerrs.append(std_coords[0].item())\n",
    "        ys.append(mean_coords[-1].item())\n",
    "        yerrs.append(std_coords[-1].item())\n",
    "        sizes.append(size)\n",
    "        colors.append(color)\n",
    "\n",
    "    assert len(colors) == len(xs)\n",
    "\n",
    "    colors = np.array(colors).squeeze()\n",
    "    # colors /= colors.max()\n",
    "\n",
    "    colsm.set_array(colors)\n",
    "\n",
    "    for x, y, xerr, yerr, color, size in zip(xs, ys, xerrs, yerrs, colors, sizes):\n",
    "        ax.errorbar(x, y, xerr=xerr, yerr=yerr, c=colsm.to_rgba(color, alpha=0.7), alpha=0.7, fmt='o')\n",
    "    # ax.scatter(xs, ys, s=sizes, c=colors, cmap='viridis', alpha=0.7)\n",
    "\n",
    "    ax.set_xlabel('First Dimension')\n",
    "    ax.set_ylabel('Last Dimension')\n",
    "    ax.set_title('Mean with Error Bars')\n",
    "\n",
    "    # Create a colorbar\n",
    "    cax = make_axes_locatable(ax).append_axes('right', size='5%', pad=0.1)\n",
    "    cbar = plt.colorbar(colsm, cax=cax)\n",
    "    cbar.set_label('Standard Deviation along Second Dimension')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = labels >= 0\n",
    "\n",
    "masked_data = SimTransientData(x=net_data.x[mask], y= net_data.y[mask]).cpu()\n",
    "masked_issimulated=masked_data.y.bool()\n",
    "data = data.cpu()\n",
    "masked_sizes = sizes[mask].cpu()\n",
    "\n",
    "# plot_data(data.x, (0.01, 0.5), issimulated, keys)\n",
    "plot_data(masked_data.x, masked_sizes, masked_issimulated, keys)\n",
    "plot_clusters(masked_data.x[:, 1:4], masked_sizes, labels[mask].squeeze(), keys[1:4], figsize=(6,6))\n",
    "plot_data(data.x, (0.0, 0.5), issimulated, keys)\n",
    "plot_mean_with_errorbars(masked_data.x[:, 1:4], labels, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 2\n",
    "tensor = data.x[:, 1:4]\n",
    "overlabels = np.full_like(mask, fill_value=-1)\n",
    "overlabels[mask] = labels\n",
    "epsilon = 0.\n",
    "indices = np.where(labels == label)[0]\n",
    "old_group_coords = tensor[indices]\n",
    "coords_2d = old_group_coords[:, [0,2]]\n",
    "sec = welzl(coords_2d)\n",
    "print(((tensor[:, [0,2]].numpy() - np.array(sec.center))**2).sum() <= sec.radius + epsilon)\n",
    "group_coords = tensor[((tensor[:, [0,2]] - torch.tensor(sec.center))**2).sum(axis=1) <= sec.radius + epsilon]\n",
    "print(len(old_group_coords))\n",
    "print(group_coords)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(*group_coords.T, c=\"blue\")\n",
    "ax.scatter(*old_group_coords.T, c=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_light_curves(tensor, labels, time_threshold=np.inf, bins=50, epsilon=0):\n",
    "    unique_labels = np.unique(labels)\n",
    "\n",
    "    for label in unique_labels:\n",
    "        if label == -1: continue\n",
    "        indices = np.where(labels == label)[0]\n",
    "        group_coords = tensor[indices]\n",
    "        coords_2d = group_coords[:, [0,2]]\n",
    "        center, radius = smallest_enclosing_circle(coords_2d)\n",
    "        group_coords = tensor[euclidean(tensor[:, [0,2]], center) <= radius + epsilon]\n",
    "        time_dev = torch.std(group_coords[:, 1], dim=0)  # Standard deviation along the second dimension\n",
    "        if time_dev > time_threshold: continue\n",
    "\n",
    "        plt.hist(group_coords[:, 1].numpy(), bins=bins)\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.title(f\"Cluster #{label}\")\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlabels = np.full_like(mask, fill_value=-1)\n",
    "overlabels[mask] = labels\n",
    "plot_light_curves(data.x[:, 1:4], overlabels, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "import torch\n",
    "\n",
    "def my_get_clusters_with_pruning(net_data, distances, model, layers, quantile, transform, plot_every=1, plot_after = 0, spectrum=True, max_threshold=0.5):\n",
    "    elaborated_data = torch.ones_like(net_data.x[:, 0].unsqueeze(-1))\n",
    "    # issimulated=net_data.y.bool()\n",
    "\n",
    "    for i in range(layers):\n",
    "        elaborated_data += model.forward(elaborated_data, net_data.edge_index)#, edge_weight=gaussian_kernel(distances, distances.median()*1000))\n",
    "        sizes = elaborated_data[:,0]\n",
    "        # threshold = torch.quantile(sizes,  quantile).item()\n",
    "        threshold = min(sizes.mean().item(), max_threshold)\n",
    "        mask = sizes >= threshold\n",
    "        net_data = transform(SimTransientData(x=net_data.x[mask], y= net_data.y[mask]))\n",
    "        if (i+1)%plot_every == 0 and i >= plot_after:\n",
    "            plot_data(net_data.x.cpu(), sizes[mask].cpu(), issimulated=net_data.y.cpu().bool(), keys=keys, title=f\"iteration {i+1}\", outfile=osp.join(\"video_frames\", f\"frame_{i:02}.png\"))\n",
    "        elaborated_data /= elaborated_data.max()\n",
    "        elaborated_data = elaborated_data[mask]\n",
    "\n",
    "\n",
    "    masked_data = net_data.cpu()\n",
    "    masked_sizes = sizes[mask].cpu()\n",
    "\n",
    "    if spectrum:\n",
    "        cluster = SpectralClustering(affinity=\"nearest_neighbors\", n_neighbors=8, assign_labels=\"cluster_qr\", n_jobs=-1)\n",
    "        labels = cluster.fit_predict(masked_data.x[:, 1:])\n",
    "    else:\n",
    "        dbscan = DBSCAN(eps=distances.median().item()/2, min_samples=5)  # Adjust parameters according to your data\n",
    "        labels = dbscan.fit_predict(masked_data.x[:, 1:])\n",
    "\n",
    "    return masked_data, masked_sizes, labels, mask.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "# filename = osp.join(\"test.onD\", \"Icaro\", \"raw\", \"0694730101\", \"pps\", \"P0694730101PNS003PIEVLF0000.FTZ\") # hard example\n",
    "filename = osp.join(\"test.onD\", \"Icaro\", \"raw\", \"0690751601\", \"pps\", \"P0690751601M2S002MIEVLF0000.FTZ\") # easy example\n",
    "# filename = osp.join(\"test.onD\", \"Icaro\", \"raw\", \"0744440301\", \"pps\", \"P0744440301M1S001MIEVLF0000.FTZ\") # medium example\n",
    "keys = [\"PI\", \"X\", \"TIME\", \"Y\"]\n",
    "k = 8\n",
    "layers = 30\n",
    "quantile = 0.6\n",
    "\n",
    "raw_data = get_raw_data(filename=filename, keys=keys, filters={\"FLAG\": (0,4)})\n",
    "\n",
    "data = SimTransientData(x = torch.from_numpy(np.array([raw_data[key] for key in keys]).T).float(),\n",
    "                        y = torch.from_numpy(np.array(raw_data[\"ISSIMULATED\"])).long()).cuda()\n",
    "\n",
    "transform = ttr.KNNGraph(k=k, force_undirected=True)\n",
    "\n",
    "net_data =transform(data)\n",
    "\n",
    "distances = torch.norm(net_data.x[net_data.edge_index[0]] - net_data.x[net_data.edge_index[1]], dim=1)\n",
    "\n",
    "model = SimpleMessage()\n",
    "\n",
    "issimulated = data.y.bool().cpu()\n",
    "\n",
    "masked_data, masked_sizes, labels, mask = \\\n",
    "    my_get_clusters_with_pruning(net_data, distances, model, layers, quantile, transform, plot_every=5, plot_after=5, spectrum=False)\n",
    "\n",
    "masked_issimulated=masked_data.y.bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = data.cpu()\n",
    "issimulated = issimulated.cpu()\n",
    "\n",
    "plot_data(data.x, (0.01, 0.5), issimulated, keys)\n",
    "plot_data(masked_data.x, masked_sizes, masked_issimulated, keys)\n",
    "plot_clusters(masked_data.x[:, 1:4], masked_sizes, labels, keys[1:4])\n",
    "plot_data(data.x, (0.0, 0.5), issimulated, keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "# filename = osp.join(\"test.onD\", \"Icaro\", \"raw\", \"0694730101\", \"pps\", \"P0694730101PNS003PIEVLF0000.FTZ\") # hard example\n",
    "filename = osp.join(\"test.onD\", \"Icaro\", \"raw\", \"0690751601\", \"pps\", \"P0690751601M2S002MIEVLF0000.FTZ\") # easy example\n",
    "# filename = osp.join(\"test.onD\", \"Icaro\", \"raw\", \"0744440301\", \"pps\", \"P0744440301M1S001MIEVLF0000.FTZ\") # medium example\n",
    "keys = [\"PI\", \"X\", \"TIME\", \"Y\"]\n",
    "k = 8\n",
    "layers = 50\n",
    "quantile = 0.99\n",
    "\n",
    "raw_data = get_raw_data(filename=filename, keys=keys, filters={\"FLAG\": (0,4)})\n",
    "\n",
    "issimulated = torch.from_numpy(np.array(raw_data[\"ISSIMULATED\"])).bool()\n",
    "\n",
    "data = SimTransientData(x = torch.from_numpy(np.array([raw_data[key] for key in keys]).T[~issimulated]).float(),\n",
    "                        y = issimulated[~issimulated].long()).cuda()\n",
    "\n",
    "transform = ttr.KNNGraph(k=k, force_undirected=True)\n",
    "\n",
    "net_data =transform(data)\n",
    "\n",
    "distances = torch.norm(net_data.x[net_data.edge_index[0]] - net_data.x[net_data.edge_index[1]], dim=1)\n",
    "\n",
    "model = SimpleMessage()\n",
    "\n",
    "issimulated = data.y.bool().cpu()\n",
    "\n",
    "masked_data, masked_sizes, labels, mask = \\\n",
    "    my_get_clusters_with_pruning(net_data, distances, model, layers, quantile, transform, plot_every=5, plot_after=15, spectrum=False, max_threshold=0.90)\n",
    "\n",
    "masked_issimulated=masked_data.y.bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = data.cpu()\n",
    "issimulated = issimulated.cpu()\n",
    "\n",
    "plot_data(data.x, (0.01, 0.5), issimulated, keys)\n",
    "plot_data(masked_data.x, masked_sizes, masked_issimulated, keys)\n",
    "plot_clusters(masked_data.x[:, 1:4], masked_sizes, labels, keys[1:4])\n",
    "plot_data(data.x, (0.0, 0.5), issimulated, keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
